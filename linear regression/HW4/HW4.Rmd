---
title: "STAT UN2103 HW4"
author: "Rebekah Kim"
date: "November 23, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Problem 1 (handwritten in back)

### Problem 2

```{r}
d <- read.table("HW4Problem2.txt", header = TRUE)

model <- lm(RentalRates~Age+OperatingExpense+VacancyRates+SquareFootage, data = d)
summary(model)

```
i)

$H_0 : \beta_1 = 0,\space H_A : \beta_3 \neq 0$

$t_{calc} = 0.570, p-value = 0.57 > 0.05$

We fail to reject the null hypothesis; therefore, x3 (vacancy rate) is not a statistically predictor to the response variable (rental rates) after holding all other variables constant.

ii)

$H_0 : \beta_1 = \beta_3 = 0, \space H_A : \beta_1 \neq 0 \space or \space \beta_3 \neq 0$

Full model:
$Y_i = \beta_0 + \beta_1x_{i1}+ \beta_2x_{i2}+ \beta_3x_{i3}+ \beta_4x_{i4}+ \epsilon_i$

$df_F = n - p = n - 5 = 81 - 5 = 76$

Reduced model:
$Y_i = \beta_0 + \beta_2x_{i2}+ \beta_4x_{i4}+ \epsilon_i$

$df_R = n - p = n - 3 = 81 - 3 = 78$

```{r}
r_model.1 <- lm(RentalRates~OperatingExpense+SquareFootage, data = d)
```
$f_{calc} = \dfrac{SSE_R - SSE_F}{df_R - df_F} \div \dfrac{SSE_F}{df_F}$

```{r}
#Shortcut
anova(r_model.1, model)
```

$SSE_F = 98.231$

$SSE_R = 159.491$

$f_{calc} = 23.968, \space p-value = 1.003e-08 < 0.05$

Therefore we reject the null hypothesis; age (x1) or vacancy rate (x3) may influence the rental rates.

iii)

$H_0 : \beta_3 = 0, \space H_A : \beta_3 \neq 0$

Full model:
$Y_i = \beta_0 + \beta_1x_{i1}+ \beta_2x_{i2}+ \beta_3x_{i3}+ \beta_4x_{i4}+ \epsilon_i$

$df_F = n - p = n - 5 = 81 - 5 = 76$

Reduced model:
$Y_i = \beta_0 + \beta_1x_{i1}+ \beta_2x_{i2}+ \beta_4x_{i4}+ \epsilon_i$

$df_R = n - p = n - 4 = 81 - 4 = 77$

```{r}
r_model.2 <- lm(RentalRates~Age+OperatingExpense+SquareFootage, data = d)
```
$f_{calc} = \dfrac{SSE_R - SSE_F}{df_R - df_F} \div \dfrac{SSE_F}{df_F}$

```{r}
#Shortcut
anova(r_model.2, model)
```

$SSE_F = 98.231$

$SSE_R = 98.650$

$f_{calc} = 0.3248, \space p-value = 0.5704 > 0.05$

Therefore, we fail to reject the null hypothesis; vacancy rate (x3) is not a statistically signficant predictor for the response variable (rental rates) after holding all other variables constant.

The f-calc and p-value (0.57) here are the same as that of the t-test (f = t^2 ; 0.3248 = 0.57^2) from part (i) as expected and therefore we reach the same conclusion: fail to reject null hypothesis.

iv)

$H_0 : \beta_3 = 0, \space H_A : \beta_3 \neq 0$

```{r}
model_t1 <- lm(RentalRates~Age+OperatingExpense+SquareFootage+VacancyRates, data = d)

anova(model_t1)
```

$f_{calc} = 0.3248, \space p-value = 0.5704 > 0.05$

We fail to reject the null hypothesis; vacancy rates (x3) is not a statistically significant predictor of rental rates (y) after holding other variables constant. The f-calc and p-value (0.57) here are the same as that of the t-test (f = t^2 ; 0.3248 = 0.57^2) from part (i) and that of the F-test from part (iii) as expected and therefore we reach the same conclusion: fail to reject null hypothesis.

v)

```{r}
x.h <- data.frame(Age = c(5,6,14,12), OperatingExpense = c(8.25, 8.5, 11.5, 10.25), VacancyRates = c(0, 0.23, 0.11, 0), SquareFootage = c(250000, 270000, 300000, 310000))

predict(model, x.h, interval = "confidence", level = 1 - 0.5/4)
```
 1.  (15.36676, 16.22950)
 2.  (15.66156, 16.39351)
 3.  (15.55610, 16.24534)
 4.  (15.44142, 16.24535)

### Problem 3
i)

```{r}
d_2 <- read.table("HW4Problem3.txt", header = TRUE)

model <- lm(y~x, data = d_2)
summary(model)

```
$y = -0.5802 + 15.0352x$

ii)
```{r}
n <- length(d_2[,1])

par(mfrow=c(2,3))

plot(d_2$x,d_2$y, main="Scatter Plot", xlab = "x", ylab = "y")
abline(a =  -0.5802, b = 15.0352)

qqnorm(rstudent(model), main = "QQ-Plot")
abline(a=0, b=1,lty=3)

hist(rstudent(model), main = "Histogram")

plot(1:n, rstudent(model), main = "Line Plot", ylab="Deleted residuals")
abline(h = 0, lty = 3)
lines(1:n,rstudent(model),col=2)

plot(predict(model), rstudent(model), main= "Residual plot", xlab = "y-hat", ylab = "Deleted residuals")
abline(h = 0, lty = 3)
lines(supsmu(predict(model), rstudent(model)), col=2)

plot(d_2$x, rstudent(model), main = "Residual Plot", xlab = "x", ylab = "Deleted residuals")
abline(h = 0, lty = 3)
lines(supsmu(d_2$x, rstudent(model)), col = 2)

```

Since the graphs are not crystal clear, there can be subjective judgments. This is what I see: the scatter plot seems to suggest that the response function is linear (clear linear pattern). The QQ-plot suggests that is is safe to assume normality of the error (relatively lines up well in the 45 degree line). It is a bit heavy-tailed on the left; there are some potential outliers that deviate from the 45 degree line, but generally seems to land on the line. The line plot shows that it would not be unreasonable to assume the errors are independent; there is no clear pattern and it seems like white noise. It is a bit difficult to decide the homoscedasticity of the data. The residual plots show that fluctuations in the deleted residual's overall shape; the scatters seem to get wider towards the right, having a small megaphone shape from the middle to the right section of the plot. If this is true, there would be no constance in error variance. However, these fluctuations may be due to random chance and the errors may have constant variance. 

iii)
```{r}

library(MASS)
x <- d_2$x
y <- d_2$y
bac.box <-  boxcox(y~x)
bac.lambda <-  bac.box$x[which(bac.box$y==max(bac.box$y))]
bac.lambda

```

It probably wouldn't be necessary to perform this transformation since lambda is close to 1 and its interval includes 1. The plots from part ii) already reasonably resemble a linear relationship between x and y.

### Problem 4
$H_0 : E[Y] = \beta_0 + \beta_1x \space H_A : E[Y] \neq \beta_0 +\beta_1x$
```{r}
d_3 <- read.table("1_22.txt")

x <- d_3$V2
y <- d_3$V1
n <- length(y)
c <- 4

sse.R <- anova(lm(y~x))[[2]][2]
fac.x <- factor(x)
sse.F <- anova(lm(y~fac.x))[[2]][2]
f.calc <- ((sse.R - sse.F)/(c-2))/(sse.F/(n-c))
f.calc
1-pf(f.calc, c-2, n-c)
```
$f_{calc} = 0.8237 \space p-value = 0.4622 > 0.05$

Therefore we fail to reject the null hypothesis; there may be a linear relationship between the elapsed time (x) and the hardness of the plastic (y). A linear relationship is probably appropriate for this dataset as further illustrated in the plot below.

```{r}
plot(x, y)
abline(lm(y~x))
```

### Problem 5 (handwritten in back)
