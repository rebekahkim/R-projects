# regression model diagnostics

### data loading: Delivery time data (Example 4.1 in the textbook)

install.packages("robustbase")
library(robustbase)

X0<-delivery
colnames(X0)<-c('Cases','Distance','Time')

# Delivery Time Data, from Montgomery and Peck (1982). The aim is to explain the time required to
# service a vending machine (Y) by means of the number of products stocked (X1) and the distance
# walked by the route driver (X2).

plot(X0)


### plotting example: color, point character and point size

ind_dist_600<-which(X0[,2]>600) # which(ll <- c(TRUE, FALSE, TRUE, NA, FALSE, FALSE, TRUE))
ind<-rep(4,nrow(X0))
ind[ind_dist_600]<-2
plot(X0,pch=ind,col=ind,cex=0.8) # Googling "r plot option"

# additional package : ggplot2

### multiple linear regression

Y<-X0[,3]
X<-as.matrix(cbind(rep(1,nrow(X0)),X0[,-3]))
colnames(X)[1]<-'Intercept'
fit<-lm(Y~0+X)
summary(fit)


### residual analysis

resid<-fit$resid
mse<-sum(resid^2)/(nrow(X0)-2-1)
std_resid<-resid/sqrt(mse)
H_mat<-X%*%solve(t(X)%*%X)%*%t(X)
h<-diag(H_mat)
stud_resid<-std_resid/sqrt(1-h)


### residual analysis - model checking 1: residual plots

# fitted vs. observed response plot
windows()
plot(fit$fitted,X0$Time,
     xlab='Fitted Y',ylab='Observed Y',
     xlim=c(0,90),ylim=c(0,90),xaxs='i',yaxs='i')
abline(coef=c(0,1),col=8)

# identify(fit$fitted,X0$Time,n=2)

windows()
par(mfrow=c(2,2))
plot(std_resid,type='b',
     xlab='Observation ID',ylab='Standardized residual',
     ylim=c(-2.5,2.5))
abline(h=c(-2,0,2),col=c(2,8,2),lty=c(2,1,2))

plot(stud_resid,type='b',
     xlab='Observation ID',ylab='Studentized residual',
     ylim=c(-4,4))
abline(h=c(-2,0,2),col=c(2,8,2),lty=c(2,1,2))

plot(fit$fitted,std_resid,
     xlab='Fitted value',ylab='Standardized residual',
     ylim=c(-2.5,2.5))
abline(h=c(-2,0,2),col=c(2,8,2),lty=c(2,1,2))

plot(fit$fitted,stud_resid,
     xlab='Fitted value',ylab='Studentized residual',
     ylim=c(-4,4))
abline(h=c(-2,0,2),col=c(2,8,2),lty=c(2,1,2))



### residual analysis - model checking 2: normal probability plot

windows()
par(mfrow=c(2,1))
plot(sort(std_resid),qnorm(((1:length(Y))-0.5)/length(Y)),
     xlab='Standardized residual',ylab='Normal quantile')
abline(coef=c(0,1),col=8)
plot(sort(stud_resid),qnorm(((1:length(Y))-0.5)/length(Y)),
     xlab='Studentized residual',ylab='Normal quantile')
abline(coef=c(0,1),col=8)


### residual analysis - regression diagnostics: leverage, influential point

# leverage
windows()
plot(X0$Cases,X0$Time,
     xlab='Cases',ylab='Delivery Time')
# identify(X0$Cases,X0$Time,n=2)

windows()
plot(X0$Distance,X0$Time,
     xlab='Distance',ylab='Delivery Time')
# identify(X0$Distance,X0$Time,n=2)

2*(ncol(X))/nrow(X)
cbind(order(h,decreasing=T),round(sort(h,decreasing=T),3))

# influential point checking
fit_ex1<-lm(Y[-1]~0+X[-1,])
fit_ex9<-lm(Y[-9]~0+X[-9,])
fit_ex22<-lm(Y[-22]~0+X[-22,])

fit_coef<-cbind(fit$coef,fit_ex1$coef,fit_ex9$coef,fit_ex22$coef)
colnames(fit_coef)<-c('Full','Ex.1','Ex.9','Ex.22')
round(fit_coef,3)

# Cook's distance
Cook<-cooks.distance(fit)
windows()
plot(Cook,cex=0.8,type='b',
     xlab='Observation ID',ylab="Cook's distance")
ind_infl<-which(Cook>1)
abline(h=1,col=8)
identify(Cook,n=2)

# Frankly...
windows()
par(mfrow=c(2,2))
plot(fit)

### Exercise in class:
### Diagnose the linear regression model 
### based on the data excluding the 9th observation.



#####
##### tranformation on response: Box-Cox transformation (variance stabilization)
#####

library(MASS)
boxcox(fit)
